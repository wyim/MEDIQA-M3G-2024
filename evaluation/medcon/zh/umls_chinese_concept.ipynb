{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install QuickUMLS\n",
    "#!python -m quickumls.install <umls_installation_path> <destination_path> -E CHI\n",
    "#Then move the MRCONSO.RRF to <umls_installation_path/META>, and replace the original MRCONSO.RRF file\n",
    "#MRCONSO.RRF was created based on the manually collected UMLS_CHI_v02.xlsx file in QuickUMLS's format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting CHI Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_from_response</th>\n",
       "      <th>UMLS_term</th>\n",
       "      <th>cui</th>\n",
       "      <th>type</th>\n",
       "      <th>semantic_subtype</th>\n",
       "      <th>CHI_term</th>\n",
       "      <th>ENG_URL</th>\n",
       "      <th>CHI_URL</th>\n",
       "      <th>machine_translated</th>\n",
       "      <th>type_modified</th>\n",
       "      <th>CHI_term_modified</th>\n",
       "      <th>concept added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deformity</td>\n",
       "      <td>deformity</td>\n",
       "      <td>C0000768|C2117111|C0302142</td>\n",
       "      <td>Disease</td>\n",
       "      <td>,Congenital Abnormality ,Finding ,Anatomical A...</td>\n",
       "      <td>畸形</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Deformity</td>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2</td>\n",
       "      <td>0</td>\n",
       "      <td>Disease</td>\n",
       "      <td>畸形</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malformation</td>\n",
       "      <td>deformity</td>\n",
       "      <td>C0000768|C2117111|C0302142</td>\n",
       "      <td>Disease</td>\n",
       "      <td>,Congenital Abnormality ,Finding ,Anatomical A...</td>\n",
       "      <td>畸形</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Deformity</td>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2</td>\n",
       "      <td>0</td>\n",
       "      <td>Disease</td>\n",
       "      <td>畸形</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malformations</td>\n",
       "      <td>deformity</td>\n",
       "      <td>C0000768|C2117111|C0302142</td>\n",
       "      <td>Disease</td>\n",
       "      <td>,Congenital Abnormality ,Finding ,Anatomical A...</td>\n",
       "      <td>畸形</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Deformity</td>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2</td>\n",
       "      <td>0</td>\n",
       "      <td>Disease</td>\n",
       "      <td>畸形</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abscess</td>\n",
       "      <td>abscess</td>\n",
       "      <td>C0000833</td>\n",
       "      <td>Disease</td>\n",
       "      <td>,Disease or Syndrome</td>\n",
       "      <td>脓疡</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abscess</td>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E8%86%BF%E7%98%8D</td>\n",
       "      <td>0</td>\n",
       "      <td>Disease</td>\n",
       "      <td>脓疡</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acanthosis</td>\n",
       "      <td>acanthosis nigricans</td>\n",
       "      <td>C0000889|C0221270</td>\n",
       "      <td>Disease</td>\n",
       "      <td>,Finding</td>\n",
       "      <td>黑棘皮症</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Acanthosis_nigri...</td>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E9%BB%91%E6%A3%...</td>\n",
       "      <td>0</td>\n",
       "      <td>Disease</td>\n",
       "      <td>黑棘皮症</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  concept_from_response             UMLS_term                         cui  \\\n",
       "0             deformity             deformity  C0000768|C2117111|C0302142   \n",
       "1          malformation             deformity  C0000768|C2117111|C0302142   \n",
       "2         malformations             deformity  C0000768|C2117111|C0302142   \n",
       "3               abscess               abscess                    C0000833   \n",
       "4            acanthosis  acanthosis nigricans           C0000889|C0221270   \n",
       "\n",
       "      type                                   semantic_subtype CHI_term  \\\n",
       "0  Disease  ,Congenital Abnormality ,Finding ,Anatomical A...       畸形   \n",
       "1  Disease  ,Congenital Abnormality ,Finding ,Anatomical A...       畸形   \n",
       "2  Disease  ,Congenital Abnormality ,Finding ,Anatomical A...       畸形   \n",
       "3  Disease                               ,Disease or Syndrome       脓疡   \n",
       "4  Disease                                           ,Finding     黑棘皮症   \n",
       "\n",
       "                                             ENG_URL  \\\n",
       "0            https://en.wikipedia.org/wiki/Deformity   \n",
       "1            https://en.wikipedia.org/wiki/Deformity   \n",
       "2            https://en.wikipedia.org/wiki/Deformity   \n",
       "3              https://en.wikipedia.org/wiki/Abscess   \n",
       "4  https://en.wikipedia.org/wiki/Acanthosis_nigri...   \n",
       "\n",
       "                                             CHI_URL  machine_translated  \\\n",
       "0   https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2                   0   \n",
       "1   https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2                   0   \n",
       "2   https://zh.wikipedia.org/wiki/%E7%95%B8%E5%BD%A2                   0   \n",
       "3   https://zh.wikipedia.org/wiki/%E8%86%BF%E7%98%8D                   0   \n",
       "4  https://zh.wikipedia.org/wiki/%E9%BB%91%E6%A3%...                   0   \n",
       "\n",
       "  type_modified CHI_term_modified  concept added  \n",
       "0       Disease                畸形            NaN  \n",
       "1       Disease                畸形            NaN  \n",
       "2       Disease                畸形            NaN  \n",
       "3       Disease                脓疡            NaN  \n",
       "4       Disease              黑棘皮症            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('UMLS_CHI_v02.xlsx')\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique CHI_term and type combinations\n",
    "df_aggregated = df.groupby(['CHI_term_modified', 'type_modified']).agg(lambda x: ','.join(set([str(i) for i in x if pd.notnull(i)]))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickumls import QuickUMLS\n",
    "\n",
    "quickumls_filepath = '{}/data/quickUMLS_CHI'\n",
    "matcher = QuickUMLS(quickumls_filepath, threshold=0.7, min_match_length=1, window = 20)\n",
    "\n",
    "def find_matches(text, matcher, df_aggregated):\n",
    "    matches = matcher.match(text, best_match=True, ignore_syntax=False)\n",
    "    terms = {}\n",
    "    for match in matches:\n",
    "        for candidate in match:\n",
    "            term = candidate['term']\n",
    "            cui = candidate['cui']\n",
    "            if term in terms:\n",
    "                terms[term]['cui'].add(cui)\n",
    "            else:\n",
    "                terms[term] = {'cui': {cui}, 'type': None, 'semantic_subtype': None}\n",
    "                \n",
    "    for term in terms.keys():\n",
    "        matching_row = df_aggregated[df_aggregated['CHI_term_modified'] == term]\n",
    "        if not matching_row.empty:\n",
    "            terms[term]['type'] = matching_row['type_modified'].iloc[0]\n",
    "            terms[term]['semantic_subtype'] = matching_row['semantic_subtype'].iloc[0]\n",
    "        \n",
    "    extracted_terms = [\n",
    "        {\n",
    "            'term': [term], \n",
    "            'cui': list(terms[term]['cui']),\n",
    "            'type': terms[term]['type'],\n",
    "            'semantic_subtype': [subtype.strip() for subtype in terms[term]['semantic_subtype'].split(',') if subtype.strip()],\n",
    "            'status': 'present'\n",
    "        }\n",
    "        for term in terms\n",
    "    ]\n",
    "    return extracted_terms\n",
    "\n",
    "\n",
    "find_matches(\"银屑病，似与胸腔积液没有关系\", matcher, df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM CONCEPT EXTRACTION FOR YOUR SYSTEM FILE\n",
    "import json\n",
    "\n",
    "with open(SYSTEM_PREDICTION_FILE, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for item in data:\n",
    "    for response in item['responses']:\n",
    "        text = response['content_zh']\n",
    "        matches = find_matches(text, matcher, df_aggregated)\n",
    "        response['UMLS_zh'] = matches\n",
    "\n",
    "with open(SYSTEM_PREDICTION_FILE, 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use gpt_Chinese_assertion.ipynb to insert assertion before running the following codes\n",
    "# Inserting assertion must be done before normalizing UMLS terms\n",
    "# F1 medcon score will be calculated based on the normalized UMLS terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Terms Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NORMALIZED UMLS DICTIONARY\n",
    "with open('final_UMLS_sets_CHI.json', 'r', encoding='utf-8') as f:\n",
    "    UMLS_set = json.load(f)\n",
    "\n",
    "UMLS_set.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZING MEDICAL CONCEPTS FOR YOUR SYSTEM FILE\n",
    "\n",
    "with open(SYSTEM_PREDICTION_FILE, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for item in data:\n",
    "    for response in item['responses']:\n",
    "        for term in response['UMLS_zh']:\n",
    "            umls_term = term['term']\n",
    "            for key, value in UMLS_set.items():\n",
    "                if umls_term in value['concepts']:\n",
    "                    term['term'] = key\n",
    "                    break\n",
    "\n",
    "with open(SYSTEM_PREDICTION_FILE, 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese medcon F1 Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "def read_json( file_path ) :\n",
    "    with open( file_path, 'r' ) as f :\n",
    "        return json.load( f )\n",
    "    \n",
    "\n",
    "for lang in  ['UMLS_zh']:\n",
    "    for file in glob(f'{prediction_dir}/*.json'):\n",
    "        exp=file.split('/')[-1].split('.')[0]\n",
    "        task='iiyi_test'\n",
    "\n",
    "        truth = read_json( os.path.join(reference_dir, f'{task}.json') )\n",
    "        prediction = read_json( os.path.join(prediction_dir, f'{exp}.json') )\n",
    "\n",
    "        score_path = os.path.join(score_dir, f'{exp}.json')\n",
    "        scores={} if not os.path.isfile(score_path) else read_json(score_path)\n",
    "\n",
    "        all_scores=[]\n",
    "        for pred, ref in zip(prediction,truth):\n",
    "            assert pred[\"encounter_id\"]==ref[\"encounter_id\"],1\n",
    "            NP=len(pred)\n",
    "            max_F1=0\n",
    "            \n",
    "            for p in pred['responses']:\n",
    "                p=set([(c[\"term\"][0],c[\"type\"],c.get('status','present')) for c in p[lang]])\n",
    "\n",
    "                for r in ref['responses']:\n",
    "                    r=set([(c['UMLS_term'],c[\"type\"],c.get('status','present')) for c in r[lang]])\n",
    "\n",
    "                    NT=len(r)\n",
    "                    TP=len([t for t in p if t in r])\n",
    "                    P=TP/NP if NP else 0\n",
    "                    R=TP/NT if NT else 0\n",
    "                    F1=R*P*2/(P+R) if P+R else 0\n",
    "                    max_F1=max(max_F1,F1)\n",
    "                    \n",
    "            pred[lang+' F1']=max_F1\n",
    "            all_scores.append(max_F1)\n",
    "\n",
    "        with open(os.path.join(prediction_dir, f'{exp}_updated.json'), 'w') as f:\n",
    "            json.dump(prediction, f, indent=4)\n",
    "\n",
    "        scores[lang + ' F1'] = np.mean(all_scores)\n",
    "        with open(score_path, 'w') as f:\n",
    "            json.dump(scores, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
